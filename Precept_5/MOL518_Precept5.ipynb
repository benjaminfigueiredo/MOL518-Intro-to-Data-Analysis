{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In colab run this cell first to setup the file structure!\n",
    "%cd /content\n",
    "!rm -rf MOL518-Intro-to-Data-Analysis\n",
    "\n",
    "!git clone https://github.com/benjaminfigueiredo/MOL518-Intro-to-Data-Analysis.git\n",
    "%cd MOL518-Intro-to-Data-Analysis/Precept_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823922b",
   "metadata": {},
   "source": [
    "# Review session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2d129",
   "metadata": {},
   "source": [
    "### Please use the following Google Form to submit answers: https://forms.gle/haCRkk8g75vEhoBRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60416ec7",
   "metadata": {},
   "source": [
    "#### Problem 1: Catching a data thief\n",
    "\n",
    "You have been tasked by Princeton's academic integrity review board to look at an accusation of unauthorized use of data. Dr. W and Dr. L are two long time collaborators in the field of zebra bone studies who recently had a falling out. Dr. L claims that their entire dataset of zebra femur lengths was included in an analysis of Dr. W's recent paper without adequate permission or disclosure in the publication. In fact, the claim is that the fakery has been so shoddy, that Dr. W just inserted Dr. L's dataset, in its original order, in their own dataset.\n",
    "\n",
    "You have been given access to both datasets in the data folder. In both cases, the data is being given as a CSV table with a header, reporting femur lengths in units of mm.\n",
    "\n",
    "Since the datasets at hand are large, you decide check this claim algorithmically: you will write a function in Python that accepts as input two numpy arrays and checks whether the second is a subarray of the first.\n",
    "\n",
    "![](figs/p1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_subarray(arr : np.ndarray, subarr : np.ndarray) -> bool:\n",
    "    \"\"\"Check if subarr is a contiguous subarray of arr.\"\"\"\n",
    "    # TODO Your code here. Submit this snippet to the form!\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3f5b0",
   "metadata": {},
   "source": [
    "Test your function against a couple of examples! For this, we're going to use the **assert** statement, which throw an error if the following boolean expression does not evaluate to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = np.array([1, 2, 3, 4, 5])\n",
    "subarray1 = np.array([2, 3, 4])\n",
    "assert has_subarray(example1, subarray1) == True, \"Test case 1 failed\"\n",
    "\n",
    "example2 = np.array([1, 2, 3, 4, 5])\n",
    "subarray2 = np.array([3, 5])\n",
    "assert has_subarray(example2, subarray2) == False, \"Test case 2 failed\"\n",
    "\n",
    "example3 = np.array([1, 2, 3, 4, 5])\n",
    "subarray3 = np.array([1, 2, 3, 4, 5])\n",
    "assert has_subarray(example3, subarray3) == True, \"Test case 3 failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c4216",
   "metadata": {},
   "source": [
    "With your subarray function in hand, you can check whether Dr. L's accusation holds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd678ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_W_dataset = np.loadtxt('data/femur_length_dr_W.csv', delimiter=',', skiprows=1)\n",
    "dr_L_dataset = np.loadtxt('data/femur_length_dr_L.csv', delimiter=',', skiprows=1)\n",
    "print(f\"has_subarray(dr_W_dataset, dr_L_dataset) = {has_subarray(dr_W_dataset, dr_L_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351794a",
   "metadata": {},
   "source": [
    "### Problem 2: Probing the statistical effect of data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c224c",
   "metadata": {},
   "source": [
    "Beyond the ethical dimension of your finding above, you have to assess: does the inclusion of Dr. L's data in Dr. W's work alter the conclusion of their work? Consulting with Dr. L, you are told a concerning fact: Dr. L's data was taken entirely from measurements of the corpses of zebras grown in captivity, whereas Dr. W claims the dataset was collected from fieldwork. Since these are drastically different conditions, you are concerned the results claimed in the paper, reproduced below, may not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0982ab",
   "metadata": {},
   "source": [
    "![](figs/p2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46414ce1",
   "metadata": {},
   "source": [
    "As a first sanity check, you decide to compute whether Dr. L's zoo data is plausibly distinct, in distribution, from Dr. W's actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7143f642",
   "metadata": {},
   "source": [
    "First, you need to extract Dr W's actual dataset. For this, you write a function **remove_subarray** that takes two input arrays and removes the first occurence of a subarray if it occurs, otherwise returning the original array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2dbb6b",
   "metadata": {},
   "source": [
    "![](figs/p2_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subarray(arr : np.ndarray, subarr : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Remove the first occurrence of subarr from arr.\"\"\"\n",
    "    # TODO Your code here. Submit this snippet to the form!\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ae027",
   "metadata": {},
   "source": [
    "Again, we should test whether this function behaves as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfef2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(remove_subarray(example1, subarray1), np.array([1, 5])), \"Test case 1 failed\"\n",
    "assert np.array_equal(remove_subarray(example2, subarray2), example2), \"Test case 2 failed\"\n",
    "assert np.array_equal(remove_subarray(example3, subarray3), np.array([])), \"Test case 3 failed\"\n",
    "\n",
    "# Does your function remove every occurance of the subarray, or just the first one?\n",
    "example4 = np.array([1, 2, 3, 4, 5, 2, 3, 4])\n",
    "subarray4 = np.array([2, 3, 4])\n",
    "assert np.array_equal(remove_subarray(example4, subarray4), np.array([1, 5, 2, 3, 4])), \"Test case 4 failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c0303",
   "metadata": {},
   "source": [
    "With this, you can reconstruct the original data Dr. W was presumably working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_W_original_dataset = remove_subarray(dr_W_dataset, dr_L_dataset)\n",
    "\n",
    "# Look at histograms of the original dataset, Dr. L's dataset, and the modified dataset with the subarray removed, side by side.\n",
    "# We create 3 subplots in a single row to display the histograms side by side.\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(dr_W_dataset, bins=20, label=\"Dr. W's dataset\")\n",
    "plt.title(\"Dr. W's Reported Dataset\")\n",
    "plt.xlabel(\"Femur Length (mm)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(dr_L_dataset, bins=20, label=\"Dr. L's dataset\", color='orange')\n",
    "plt.xlabel(\"Femur Length (mm)\")\n",
    "plt.title(\"Dr. L's Dataset\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(dr_W_original_dataset, bins=20, label=\"Dr. W's Reconstructed Dataset\", color='green')\n",
    "plt.xlabel(\"Femur Length (mm)\")\n",
    "plt.title(\"Dr. W's Reconstructed Dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd317d",
   "metadata": {},
   "source": [
    "You recall from class that one basic way to test whether two distributions differ *at the level of their mean* is the **two-sample t-test**.\n",
    "\n",
    "Suppose we have two samples:\n",
    "\n",
    "- Sample A: \\($ x_1, \\dots, x_{n_A} $\\)\n",
    "- Sample B: \\($ y_1, \\dots, y_{n_B} $\\)\n",
    "\n",
    "Let\n",
    "\n",
    "$\n",
    "\\bar{x} = \\text{mean of sample A}, \\quad\n",
    "\\bar{y} = \\text{mean of sample B}\n",
    "$\n",
    "\n",
    "and let\n",
    "\n",
    "$\n",
    "s_x^2, \\; s_y^2\n",
    "$\n",
    "\n",
    "be the sample variances.\n",
    "\n",
    "The test statistic (Welch’s t-test, which does not assume equal variances) is\n",
    "\n",
    "$\n",
    "t = \\frac{\\bar{x} - \\bar{y}} {\\sqrt{\\frac{s_x^2}{n_A} + \\frac{s_y^2}{n_B}}}.\n",
    "$\n",
    "\n",
    "Intuitively:\n",
    "\n",
    "- The numerator measures how far apart the sample means are.\n",
    "- The denominator estimates the **standard error** of that difference.\n",
    "- So \\( t \\) measures the mean difference in units of its expected variability.\n",
    "\n",
    "Because we estimate the variances from data, the statistic follows a **t-distribution** with approximately\n",
    "\n",
    "$\n",
    "\\nu = \\frac{\\left(\\frac{s_x^2}{n_A} + \\frac{s_y^2}{n_B}\\right)^2}{\\frac{(s_x^2/n_A)^2}{n_A - 1}+\\frac{(s_y^2/n_B)^2}{n_B - 1}}\n",
    "$\n",
    "\n",
    "degrees of freedom (Welch–Satterthwaite approximation).\n",
    "\n",
    "Finally, the **p-value** is computed as\n",
    "\n",
    "$ p = P\\big(|T_\\nu| > |t|\\big),$\n",
    "\n",
    "that is, the probability (under the null hypothesis that the two population means are equal) of observing a t-statistic at least as extreme as the one we obtained.\n",
    "\n",
    "If this p-value is small, it suggests that the observed difference in means is unlikely to be due to random sampling variation alone. \n",
    "\n",
    "Since this seems like a good enough basic metric, you decide to test the hypothesis that the two samples have equal mean:\n",
    "\n",
    "$H_0 : \\bar{x^*} = \\bar{y}$,\n",
    "\n",
    "where $x^*$ is the reconstructed sample from Dr. W's data, and $y$ is Dr. L's sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the CDF of the t-distribution from scipy.stats to compute the p-value in our t-test function.\n",
    "# The actual analytical form of the t-distribution is a bit complicated, so we rely on scipy to compute it for us.\n",
    "# (If you're curious, you can look up the formula for the t-distribution online!)\n",
    "# https://en.wikipedia.org/wiki/Student%27s_t-distribution\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_statistic(sample1 : np.ndarray, sample2 : np.ndarray) -> float:\n",
    "    \"\"\"Calculate the t-statistic and Welch-Satterthwaite d.o.f for two samples.\"\"\"\n",
    "    sample1_mean = np.mean(sample1)\n",
    "    sample2_mean = np.mean(sample2)\n",
    "    # We also need to compute the sample variances for the two samples. \n",
    "    # Remember to use ddof=1 to get the sample variance, with the denominator n-1 instead of n!\n",
    "    sample1_var = np.var(sample1, ddof=1)\n",
    "    sample2_var = np.var(sample2, ddof=1)\n",
    "    # Now we have to define the t-statistic formula.\n",
    "    # TODO Your code here. Submit this snippet to the form!\n",
    "    return 0.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e443f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(arr1 : np.ndarray, arr2 : np.ndarray) -> float:\n",
    "    \"\"\"Perform a t-test to compare the means of arr1 and arr2. Return the t-statistic and p-value.\"\"\"\n",
    "    # First we need to calculate the t-statistic using the function we just defined.\n",
    "    t_stat, dof = t_statistic(arr1, arr2)\n",
    "    # Now we compute the p-value using the cumulative distribution function (CDF) of the t-distribution.\n",
    "    # Note that this is a two-tailed test, so we need to multiply the one-tailed p-value by 2.\n",
    "    p = 2 * (1 - t.cdf(abs(t_stat), df=dof))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7189c893",
   "metadata": {},
   "source": [
    "Having defined the p-test, you go ahead, define an $\\alpha$ value, and test whether the two datasets have compatible means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your alpha threshold for statistical significance\n",
    "alpha = # TODO Your choice here!\n",
    "# Now we can perform the t-test on our two datasets and check if the p-value is less than our alpha threshold.\n",
    "p_value = t_test(dr_W_original_dataset, dr_L_dataset)\n",
    "print(f\"P-value: {p_value:.3e}\")\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in femur lengths between Dr. W's and Dr. L's datasets is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in femur lengths between Dr. W's and Dr. L's datasets is NOT statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7826aa1",
   "metadata": {},
   "source": [
    "You also have access to the previously reported values Dr. W mentions in the paper, and test whether the insertion of Dr. L's data changed the result of the statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_dataset = np.loadtxt('data/femur_length_previous.csv', delimiter=',', skiprows=1)\n",
    "# We check if Dr. W's reported dataset is significantly different from the previous study's dataset.\n",
    "p_value_reported = t_test(dr_W_dataset, previous_dataset)\n",
    "print(f\"P-value comparing Dr. W's dataset to the previous study: {p_value_previous:.3e}\")\n",
    "# Now we check if the original dataset (with the subarray removed) is significantly different from the previous study's dataset.\n",
    "p_value_original = t_test(dr_W_original_dataset, previous_dataset)\n",
    "print(f\"P-value comparing Dr. W's original dataset to the previous study: {p_value_original:.3e}\")\n",
    "\n",
    "# You decide to plot the histograms of the previous study's dataset and Dr. W's original dataset in overlap\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(previous_dataset, bins=20, alpha=0.5, label='Previous Study', color='blue', density=True)\n",
    "plt.hist(dr_W_original_dataset, bins=20, alpha=0.5, label=\"Dr. W's Original Dataset\", color='green', density=True)\n",
    "plt.xlabel(\"Femur Length (mm)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.title(\"Comparison of Previous Study and Dr. W's Original Dataset\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee16ae",
   "metadata": {},
   "source": [
    "Following your report to the Office of the Dean of Faculty, Dr. W was taken into Princeton custody, never to be seen again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f1a11",
   "metadata": {},
   "source": [
    "### Problem 3: Linear regression and homoscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22919e",
   "metadata": {},
   "source": [
    "You are given access to a dataset that looks at students scores on a test as a function of the number of hours of study before the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f28b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('data/test_scores.csv', delimiter=',', skiprows=1)\n",
    "hours = dataset[:, 0]\n",
    "scores = dataset[:, 1]\n",
    "plt.scatter(hours, scores)\n",
    "plt.xlabel(\"Hours Studied\")\n",
    "plt.ylabel(\"Test Scores\")\n",
    "plt.title(\"Test Scores vs. Hours Studied\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e230dd",
   "metadata": {},
   "source": [
    "What does it look like? Evaluate the features of this dataset and propose a functional form\n",
    "\n",
    "$S = f(H) + \\epsilon,$\n",
    "\n",
    "where $S$ is the score, $H$ is the number of hours studied, $\\epsilon$ is noise and $f$ is a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(x, parameter_1, parameter_2):\n",
    "    \"\"\"A simple model to predict test scores based on hours studied.\"\"\"\n",
    "    # TODO Your code here. Submit this snippet to the form!\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b100a2",
   "metadata": {},
   "source": [
    "As you learned in class, you can fit data to your model using **scipy.optimize.curve_fit**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f66e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Fit the model to the data using curve_fit\n",
    "parameter_guess = [1,1] # TODO give a reasonable guess for the parameters\n",
    "popt, pcov = curve_fit(my_model, hours, scores, p0=parameter_guess)\n",
    "\n",
    "# Unpack the optimal parameters from popt and plot the fitted curve on top of the original data\n",
    "a_opt, b_opt = popt\n",
    "x_fit = np.linspace(0, 10, 100)\n",
    "y_fit = my_model(x_fit, a_opt, b_opt)\n",
    "plt.scatter(hours, scores, label='Data')\n",
    "plt.plot(x_fit, y_fit, color='red', label='Fitted Curve')\n",
    "plt.xlabel(\"Hours Studied\")\n",
    "plt.ylabel(\"Test Scores\")\n",
    "plt.title(\"Test Scores vs. Hours Studied with Fitted Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c31c93",
   "metadata": {},
   "source": [
    "You initially are satisfied with the result, but then you remember one of the assumptions needed in linear regression: homoscedasticity, or constant variance. Does this hold in your dataset? One way to check is to plot the residuals from the regression above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd961efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the residuals of the fitted model to check for patterns\n",
    "y_pred = my_model(hours, a_opt, b_opt)\n",
    "residuals = scores - y_pred\n",
    "plt.scatter(hours, residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Hours Studied\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals of the Fitted Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c96b4",
   "metadata": {},
   "source": [
    "What features of the residuals do you notice in this plot? Is our data homoscedastic?\n",
    "\n",
    "Heteroscesdasticity is a common problem in practice. The effect it has is not on the estimates of our parameters, but on our ability to write down confidence intervals around them. The solution to this issue is quite intuitive: points where we expect our residuals to be higher should be less informative for our fit, so we substitute the least squares algorithm by one which weight points inversely to their variance.\n",
    "\n",
    "Ordinary least squares (OLS) fits a model by minimizing\n",
    "\n",
    "$$\n",
    "\\sum_i (y_i - f(x_i))^2.\n",
    "$$\n",
    "\n",
    "Weighted Least Squares instead minimizes\n",
    "\n",
    "$$\n",
    "\\sum_i w_i (y_i - f(x_i))^2,\n",
    "$$\n",
    "\n",
    "where the weights are typically chosen as\n",
    "\n",
    "$$\n",
    "w_i = \\frac{1}{\\sigma_i^2}.\n",
    "$$\n",
    "\n",
    "Intuitively:\n",
    "\n",
    "- Points with large variance (less reliable) get **smaller weights**.\n",
    "- Points with small variance (more reliable) get **larger weights**.\n",
    "\n",
    "WLS adjusts the regression so that noisier observations influence the fit less, leading to more accurate uncertainty estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f6247",
   "metadata": {},
   "source": [
    "In Python, this is done by supplying the weights in curve_fit as a **sigma** parameter, but this itself is not robust to noise and would require a choice of discretization! One way to get around this, is by actually trying to create a model for the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa593ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We look at the squared residuals, which represent the variance of the errors.\n",
    "plt.scatter(hours, residuals**2)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Hours Studied\")\n",
    "plt.ylabel(\"Residual squared\")\n",
    "plt.title(\"Squared Residuals of the Fitted Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c96d5c",
   "metadata": {},
   "source": [
    "Looking at the residuals, you propose a model for the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40674d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_var_model(x, parameter):\n",
    "    \"\"\"A model to predict the variance of the errors based on hours studied.\"\"\"\n",
    "    # TODO Your code here. Submit this snippet to the form!\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29197141",
   "metadata": {},
   "source": [
    "Now we can fit the model to our variance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_p0 = [] # TODO give a reasonable guess for the parameters of the variance model\n",
    "var_popt, var_pcov = curve_fit(my_var_model, hours, residuals**2, p0=var_p0)\n",
    "\n",
    "# Plot the fitted variance model on top of the squared residuals to see how well it captures the pattern of heteroscedasticity.\n",
    "c_opt, d_opt = var_popt\n",
    "y_var_fit = my_var_model(x_fit, c_opt, d_opt)\n",
    "plt.scatter(hours, residuals**2, label='Squared Residuals')\n",
    "plt.plot(x_fit, y_var_fit, color='red', label='Fitted Variance Model')\n",
    "plt.xlabel(\"Hours Studied\")\n",
    "plt.ylabel(\"Residuals Squared\")\n",
    "plt.title(\"Squared Residuals and Fitted Variance Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0478d7",
   "metadata": {},
   "source": [
    "With this result in hands, you can now estimate the variance of the fitted model taking into account the heterosdasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_model = np.sqrt(my_var_model(hours, c_opt, d_opt))\n",
    "popt_weighted, pcov_weighted = curve_fit(my_model, hours, scores, sigma=sigma_model, absolute_sigma=True, p0=parameter_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2aca2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
